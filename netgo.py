"""

NetGO - Main Script

This is the main entry point for NetGO, 
all the commands can be run by running this script using python 3.x

=======
License
=======

Copyright (c) 2021 Mateo Torres <mateo.torres@fgv.br>

Permission is hereby granted, free of charge, to any person
obtaining a copy of this software and associated documentation
files (the "Software"), to deal in the Software without
restriction, including without limitation the rights to use,
copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the
Software is furnished to do so, subject to the following
conditions:

The above copyright notice and this permission notice shall be
included in all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES
OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT
HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY,
WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR
OTHER DEALINGS IN THE SOFTWARE.

"""

__author__ = 'Mateo Torres'
__email__ = 'mateo.torres@fgv.br'
__copyright__ = 'Copyright (c) 2021, Mateo Torres'
__license__ = 'MIT'
__version__ = '0.1'

import argparse
import commands
import os
import json


if __name__ == '__main__':
    parser = argparse.ArgumentParser(
        description='NetGO'
    )
    subparsers = parser.add_subparsers(help='sub-command help', dest='subcommand')

    predict = subparsers.add_parser(
        'predict',
        description='NetGO predict: given a fasta file, a path to STRING files and a directory of trained models, it'
                    'will predict function for each protein in the FASTA file using NetGO',
        help='prediciton command'
    )
    predict.set_defaults(func=commands.predict)
    predict.add_argument('--fasta', help='Path to the protein sequence file', required=True)
    predict.add_argument('--graph',
                         help='Path to the protein interactions file (should be the STRING format)',
                         required=True)
    predict.add_argument('--homologs',
                         help='A tab separated file that lists a protein in the fasta file, a protein from the '
                              'STRING database, the bit-score, and the NCBI taxonomy id of the STRING protein in '
                              'each line',
                         required=True)
    predict.add_argument('--trained-models',
                         help='Path to the pickled models, as generated by the train command',
                         required=True)
    predict.add_argument('--exclusion-list',
                         help='a text file containing one NCBI taxonomy id per line, which will be excluded from STRING '
                              'for evaluation purposes',
                         default='no_exclusions')
    predict.add_argument('--output-directory',
                         help='path to an (ideally) empty directory where prediction files will be written',
                         required=True)
    predict.add_argument('--kmer-length',
                         help='kmer length, it will be used to pre-process the fasta file, it should match the '
                              'length used during training',
                         required=True)
    predict.add_argument('--interpro-output',
                         help='InterPro output file',
                         required=True)
    predict.add_argument('--profet-output',
                         help='ProFET output file',
                         required=True)
    predict.add_argument('--blast-output',
                         help='BLAST output file for BLAST-kNN',
                         required=True)


    # predict.add_argument('--cpu', help='Number of CPUs to use for parallelisable computations', default='infer')

    train = subparsers.add_parser(
        'train',
        description='NetGO training: given a training dataset, train and save the component and the LTR models to disk',
        help='train command'
    )
    train.set_defaults(func=commands.train)
    train.add_argument('--fasta-components',
                       help='FASTA file used for training the component models',
                       required=True)
    train.add_argument('--fasta-ltr',
                       help='FASTA file used for training the LTR model',
                       required=True)
    train.add_argument('--goa-components',
                       help='GOA annotations in TSV format to be used for train the component models.'
                            'Columns are: "protein" and "goterm", no header.',
                       required=True)
    train.add_argument('--goa-ltr',
                       help='GOA annotations in TSV format to be used for train the LTR model.'
                            'Columns are: "protein" and "goterm", no header',
                       required=True)
    train.add_argument('--homologs',
                       help='A tab separated file that lists a protein in the fasta file, a protein from the '
                            'STRING database, the bit-score, trand the NCBI taxonomy id of the STRING protein in '
                            'each line',
                       required=True)
    train.add_argument('--output-directory',
                       help='path to an (ideally) empty directory where trained model files will be stored',
                       required=True)
    train.add_argument('--kmer',
                       help='KMer file: a tab separated file with columns '
                            'accession, kmer, frequency (no header)',
                       required=True)
    train.add_argument('--interpro-output',
                       help='InterPro output file',
                       required=True)
    train.add_argument('--profet-output',
                       help='ProFET output file (usually named trainingSetFeatures.csv)',
                       required=True)
    train.add_argument('--blast-output',
                       help='BLAST output file for BLAST-kNN',
                       required=True)
    train.add_argument('--goterms',
                       help='List of GO terms to create LR models. a file with a '
                            'GO term per line.',
                       default='all')
    train.add_argument('--obo',
                       help='Path to a go.obo file containing the GO structure')

    filter_gaf = subparsers.add_parser(
        'filter-gaf',
        description='NetGO filter GAF: Given a GAF file and a list of allowed GO terms, it generates'
                    'an annotation file compatible with the training and testing commands. Annotations'
                    'are uppropagated.',
        help='filter GAF utility'
    )
    filter_gaf.set_defaults(func=commands.filter_gaf)
    filter_gaf.add_argument('--gaf',
                            help='GOA annotation file in GAF format',
                            required=True)
    filter_gaf.add_argument('--allowed-terms',
                            help='text file containing allowed go term (one per line)',
                            required=True)
    filter_gaf.add_argument('--obo',
                            help='go.obo file, used to build the structure of the Gene Ontology',
                            required=True)
    filter_gaf.add_argument('--output',
                            help='output file',
                            required=True)

    args = parser.parse_args()
    args.func(args)


    # try:
    #     args.func(args)
    # except AttributeError as e:
    #     print(e)
    #     parser.parse_args(['--help'])
